from dotenv import load_dotenv
from langchain.chains.llm import LLMChain
from langchain_community.chat_models import ChatOpenAI
from langchain_core.prompts import PromptTemplate
from agents.export_excel_agent import export_test_cases_with_agent
from utils import load_prompt_template

load_dotenv()


def generate_test_cases_from_points(test_points: str, requirement: str) -> str:
    prompt_path = "prompts/generate_test_cases.md"
    prompt_text = load_prompt_template(prompt_path)

    prompt_template = PromptTemplate(
        input_variables=["requirement", "test_points"],
        template=prompt_text,
    )

    llm = ChatOpenAI(temperature=0.2, model="gpt-3.5-turbo")
    testcase_chain = LLMChain(llm=llm, prompt=prompt_template)

    response = testcase_chain.run({
        "requirement": requirement,
        "test_points": test_points
    })

    return response  # è¿”å›çš„æ˜¯ JSON å­—ç¬¦ä¸²


def main():
    # åŠ è½½å¤–éƒ¨ Prompt æ–‡ä»¶
    prompt_path = "prompts/generate_test_points.md"
    prompt_text = load_prompt_template(prompt_path)

    # è§£æ Prompt æ–‡ä»¶
    test_point_prompt_template = PromptTemplate(
        input_variables=["requirement"],
        template=prompt_text,
    )

    llm = ChatOpenAI(temperature=0, model="gpt-3.5-turbo")
    parser_chain = LLMChain(llm=llm, prompt=test_point_prompt_template)

    # ç¤ºä¾‹è°ƒç”¨
    requirement = "ç”¨æˆ·å¯ä»¥ä½¿ç”¨é‚®ç®±å’Œå¯†ç ç™»å½•ç³»ç»Ÿï¼ŒæˆåŠŸåè·³è½¬åˆ°é¦–é¡µã€‚è‹¥é‚®ç®±æˆ–å¯†ç é”™è¯¯ï¼Œåº”æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ã€‚"
    test_points = parser_chain.run(requirement)
    print(test_points)

    # Step 2: æ ¹æ®æµ‹è¯•ç‚¹ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
    test_case_json = generate_test_cases_from_points(test_points, requirement)
    print("ğŸ“„ ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ JSONï¼š\n", test_case_json)

    # Step 3: å¯¼å‡ºä¸º Excel æ–‡ä»¶
    export_test_cases_with_agent(test_case_json, filename="test_cases.xlsx")


if __name__ == "__main__":
    main()
